import numpy as np
import pandas as pd
import re


def parse_features(features, row_idx=0):
    '''A function for parsing "feature" (from genome annotation file) column in files generated by `bedtools intersect` command
    
    Parameters:
        features (iterable): list or pd.Series (column) with features
        row_idx (int): index of reference row with items from "feature" column
        
    Returns:
        features_df (pd.DataFrame): pd.DataFrame with parsed features
    '''
    
    
    features_dict = {}
    a = []
    for item in features.iloc[row_idx].split(";"):
        key, value = item.split("=")
        features_dict[key] = a

    for i in range(features.shape[0]): 
        for row in features.iloc[i].split(";"):
            row = row.split(";")
            for el in row:
                k, v = el.split("=")
                if k in features_dict.keys():
                    if features_dict[k]:
                        features_dict[k].append(v)
                    else:
                        features_dict.update({k: [v]})
                else:
                    print(f'Minor feature: {k}')

    features_df = pd.DataFrame(features_dict)
    return features_df


def parse_string(s: str) -> str:
    '''A function for compacting a string on a graph by inserting "\n"
    
    Parameters:
        s (str): string to compact
    
    Returns:
        string with inserted "\n"
    '''
    
    
    split = s.split()
    if len(split) <= 2:
        return s
    return f"{split[0]} {split[1]}" + "\n" + " ".join(split[2:])


def parse_snp_coord(dataframe, n_snps, remap=False):
    '''A function for parsing AntEpiSeeker output for generating SNP coordinates
    
    Parameters:
        dataframe (pd.DataFrame): dataframe with AntEpiSeeker results
        n_snps (int): number of interacting SNPs, or analysis mode: two-loci(2) or three-loci(3) AntEpiSeeker interaction mode
        
    Returns:
        dataframe (pd.DataFrame): input dataframe with new columns containing parsed SNP coordinates
    '''
    
    
    if remap:
        # list with chromosomes in format from AntEpiSeeker output
        chrom_ = [f"chr_{i}" if i > 9 else f"chr_0{i}" for i in range(1, 21)]

        # list with chromosomes in format for remapping
        chrom_num = [f"chr{i}" for i in range(1, 21)]

        # dictionary with chromosomes for renaming
        chrom = dict(zip(chrom_, chrom_num))

    
    for idx in range(n_snps):
        dataframe[f"SNP{idx+1}"] = dataframe[f"SNP{idx+1}"].apply(lambda x: re.split(r'[()]', x)[1])
        dataframe[f"SNP{idx+1}_chr"] = dataframe[f"SNP{idx+1}"].apply(lambda x: re.split(r':', x)[0])
        dataframe[f"SNP{idx+1}_pos"] = dataframe[f"SNP{idx+1}"].apply(lambda x: re.split(r':', x)[1])
        
        if remap:
            dataframe[f"SNP{idx+1}_chr"] = dataframe[f"SNP{idx+1}_chr"].replace(chrom)
        else:
            dataframe[f"SNP{idx+1}_chr"] = dataframe[f"SNP{idx+1}_chr"].apply(
                lambda x: x[3:] if x.startswith("chr") else x
            )
        
    return dataframe


def generate_1kb_regions(dataframe, n_snps, coord_file):
    '''A function for generating 1kb region around SNPs for genome assembly remapping in chrN:start-stop format and 
    writing these coordinates in file for genome assembly remapping
    
    Parameters:
        dataframe (pd.DataFrame): dataframe with SNP coordinates
        n_snps (int): number of interacting SNPs, or analysis mode: two-loci(2) or three-loci(3) AntEpiSeeker interaction mode
        coord_file (str): prefix for output file with generated coordinates
        
    Returns:
        dataframe (pd.DataFrame): input dataframe with new columns containing +-500bp coordinates around SNPs
    '''
    
    
    # generating coordinates +-500bp from SNP position for remapping on genome assembly v2.1
    for idx in range(n_snps):
        dataframe.loc[:, f"SNP{idx+1}+500"] = dataframe[f"SNP{idx+1}_pos"].astype(int) + 500
        dataframe.loc[:, f"SNP{idx+1}-500"] = dataframe[f"SNP{idx+1}_pos"].astype(int) - 500
        cols = [f"SNP{idx+1}-500", f"SNP{idx+1}+500"]
        dataframe.loc[:, f'coordinate{idx+1}'] = dataframe[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)
        dataframe.loc[:, f'coordinate{idx+1}'] = dataframe[[f"SNP{idx+1}_chr", f"coordinate{idx+1}"]].apply(
            lambda row: ':'.join(row.values.astype(str)), axis=1
        )
        
        # writing coordinates in file
        dataframe.to_csv(
            f"{coord_file}_{idx+1}.txt", sep='\n', 
            columns=[f"coordinate{idx+1}"], header=False, index=False
        )
    return dataframe


def generate_bed_file_aa(dataframe, chr_names_dict, bed_path):
    '''A function for replacing chromosome names with RefSeq IDs used in genome assembly v2.1 annotation for amino acide content dataset
    and generating .bed file for intersection with annotation
    
        This file containes four columns:
        1) chromosome RefSeq ID;
        2) start coordinate;
        3) stop coordinate;
        4) SNP ID
    
    Parameters:
        dataframe (pd.DataFrame): dataframe with SNP region coordinates
        chr_names_dict (dict): dictionary with chromosome names and respective IDs for renaming
        bed_path (str): prefix for output .bed file
        
    Returns:
        dataframe (pd.DataFrame): initial dataframe with replaced chromosome names and .bed coordinates
    '''
    
    
    # replacing chromosome names with RefSeq IDs
    dataframe["chr_ID"] = dataframe.loc[:, "mapped_id"].replace(chr_names_dict)
    
    # generating .bed coordinates
    dataframe[["mapped_start", "mapped_stop"]] = dataframe[["mapped_start", "mapped_stop"]].astype(int) - 1
    
    # generating .bed file
    dataframe.to_csv(f"{bed_path}.bed", sep='\t',
                      columns=["chr_ID", "mapped_start", "mapped_stop", "SNP_IDs"], 
                      header=False, index=False)
    return dataframe


def generate_bed_file_unique(dataframe, bed_path):
    '''A function for generating .bed file for intersection with genome assembly v2.1 annotation from 
    EnsemblePlants for commercial dataset
    
        This file containes four columns:
        1) chromosome name as in annotation;
        2) start coordinate;
        3) stop coordinate;
        4) SNP ID
    
    Parameters:
        dataframe (pd.DataFrame): dataframe with SNP region coordinates
        bed_path (str): prefix for output .bed file
        
    Returns:
        unique_snps_dataframe (pd.DataFrame): dataframe with replaced chromosome names and .bed coordinates for unique SNPs from all pairs
    '''
    
    
    # combining all SNPs from pairs
    unique_snps = pd.concat([dataframe["SNP1"], dataframe["SNP2"]], axis=0).unique()
    
    # generating dataframe with unique SNP IDs
    unique_snps_df = pd.DataFrame(unique_snps, columns=["SNP_ID"])
    
    # generating columns with coordinates parsing SNP IDs
    unique_snps_df["chr"] = unique_snps_df["SNP_ID"].apply(lambda x: re.split(r':', x)[0])
    unique_snps_df["pos_stop"] = unique_snps_df["SNP_ID"].apply(lambda x: re.split(r':', x)[1])
    
    # renaming chromosome as in annotation file (just numbers or scaffold names)
    unique_snps_df["chr"] = unique_snps_df["chr"].apply(
        lambda x: x[3:] if x.startswith("chr") else x
    )
    unique_snps_df["pos_start"] = unique_snps_df["pos_stop"].astype(int) - 1
    
    # generating .bed file with unique SNPs
    unique_snps_df.to_csv(
        f"{bed_path}.bed", sep='\t',
        columns=["chr", "pos_start", "pos_stop", "SNP_ID"],
        header=False, index=False)
    return unique_snps_df
    

def assign_gene_for_snp(dataframe, n_snps, snp_gene_dict):
    '''A function for assigning gene ids for SNPs
    
    Parameters:
        dataframe (pd.DataFrame): dataframe with SNP pairs
        n_snps (int): number of interacting SNPs, or analysis mode: two-loci(2) or three-loci(3) AntEpiSeeker interaction mode
        snp_gene_dict (dict)L dictionary with SNP-gene pairs
        
    Returns:
        pairs_df (pd.DataFrame): dataframe with SNP and respective gene pairs
    '''
    
    
    for idx in range(n_snps):
        # from SNPs to genes
        dataframe[f"gene{idx+1}"] = dataframe[f"SNP{idx+1}"].apply(lambda x: snp_gene_dict[x] if x in snp_gene_dict.keys() else np.nan)    
        
    # removing pairs/triplets for which respective genes were not found
    pairs_df = dataframe.dropna(axis=0)
    
    # transforming each gene pair/triplet into frozenset to filter mirrored pairs and 
    # those pairs/triplets with genes interacting with themselves
    pairs_df["setted"] = [
        frozenset(i) for i in zip(pairs_df["gene1"], pairs_df["gene2"])
    ]
    
    # sorting dataframe by "Chi-square" value
    pairs_df = pairs_df.sort_values(by="Chi-square", ascending=False)
    
    # dropping duplicated gene-gene pairs/triplets with less "Chi-square" value
    pairs_df = pairs_df.drop_duplicates(subset="setted", keep="first").reset_index(drop=True)
    
    # dropping pairs/triplets with genes interacting with themselves
    # length of a set < 2
    pairs_df = pairs_df[pairs_df["setted"].apply(lambda x: len((x)) >= 2)]
    pairs_df = pairs_df.drop(columns=["setted"])
    return pairs_df


def parse_gene_info(gene_info_df):
    '''A function for parsing file with Gene Info results generated for convertion of gene names starts with "GLYMA" to respective Gene IDs using bioloigical DataBase network and its utility for database to database conversions ([db2db](https://biodbnet.abcc.ncifcrf.gov/db/db2db.php))
    
    Parameters:
        gene_info_df (pd.DataFrame): dataframe with Gene Info conversion results
        
    Returns: 
        gene_info_df (pd.DataFrame): initial dataframe with new colomn containing parsed Gene IDs
    '''
    
    
    gene_info_df["gene_ids"] = gene_info_df["Gene Info"].apply(lambda x: x.split()[0])
    gene_info_df = gene_info_df[gene_info_df["gene_ids"] != "-"]
    return gene_info_df


def parse_kegg_results(kegg_dataframe):
    '''A function for parsing KEGG enrichment results obtained via ShinyGo v0.77
    
    Parameters:
        kegg_dataframe (pd.DataFrame): dataframe with KEGG enrichment results
        
    Returns:
        kegg_dataframe (pd.DataFrame): initial dataframe with modified and additional columns for visualization
    '''
    
    
    # parsing KEGG Pathway url to obtain Pathway ID
    kegg_dataframe.loc[:, "KEGG_ID"] = kegg_dataframe["URL"].str.split("?", expand=True)[1]

    # calculating -log10(FDR)
    kegg_dataframe.loc[:, "Enrichment FDR"] = kegg_dataframe["Enrichment FDR"].apply(lambda x: round(-np.log10(x), 1))

    # generating strings with Pathway name and its ID
    kegg_dataframe.loc[:, "KEGG_ID"] = kegg_dataframe[["Pathway", "KEGG_ID"]].agg(": ".join, axis=1)

    # inserting "\n" into long strings for prettier visualization
    kegg_dataframe.loc[:, "KEGG_ID"] = kegg_dataframe["KEGG_ID"].apply(parse_string)
    return kegg_dataframe